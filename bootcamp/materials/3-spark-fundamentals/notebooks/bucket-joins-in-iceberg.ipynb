{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b48d10-7ddc-4d74-ad45-e1b033849cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "// In python use: from pyspark.sql.functions import broadcast, split, lit\n",
    "import org.apache.spark.sql.functions.{broadcast, split, lit}\n",
    "\n",
    "val matchesBucketed = spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/matches.csv\")\n",
    "\n",
    "val matchDetailsBucketed =  spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/match_details.csv\")\n",
    "\n",
    "// spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.matches_bucketed\"\"\")\n",
    "val bucketedDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.matches_bucketed (\n",
    "    match_id STRING,\n",
    "    is_team_game BOOLEAN,\n",
    "    playlist_id STRING,\n",
    "    completion_date TIMESTAMP\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (completion_date, bucket(16, match_id));\n",
    "\"\"\"\n",
    "// spark.sql(bucketedDDL)\n",
    "\n",
    "// Partitioned table on completion_date and the 16 buckets based on match_id\n",
    "matchesBucketed\n",
    ".select(\n",
    "    $\"match_id\",\n",
    "    $\"is_team_game\",\n",
    "    $\"playlist_id\",\n",
    "    $\"completion_date\"\n",
    ")\n",
    ".write.mode(\"append\")\n",
    ".partitionBy(\"completion_date\")\n",
    ".bucketBy(16, \"match_id\")\n",
    ".saveAsTable(\"bootcamp.matches_bucketed\")\n",
    "\n",
    "val bucketedDetailsDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.match_details_bucketed (\n",
    "    match_id STRING,\n",
    "    player_gamertag STRING,\n",
    "    player_total_kills INTEGER,\n",
    "    player_total_deaths INTEGER\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (bucket(16, match_id));\n",
    "\"\"\"\n",
    "spark.sql(bucketedDetailsDDL)\n",
    "\n",
    "// Partitioned table on the 16 buckets based on match_id\n",
    "matchDetailsBucketed\n",
    ".select(\n",
    "    $\"match_id\",\n",
    "    $\"player_gamertag\",\n",
    "    $\"player_total_kills\",\n",
    "    $\"player_total_deaths\"\n",
    ")\n",
    ".write.mode(\"append\")\n",
    ".bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.match_details_bucketed\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "\n",
    "//matchesBucketed.createOrReplaceTempView(\"matches\")\n",
    "//matchDetailsBucketed.createOrReplaceTempView(\"match_details\")\n",
    "\n",
    "//spark.sql(\"\"\"\n",
    "//    SELECT * FROM bootcamp.match_details_bucketed mdb JOIN bootcamp.matches_bucketed md \n",
    "//    ON mdb.match_id = md.match_id\n",
    "//    AND md.completion_date = DATE('2016-01-01')\n",
    "//        \n",
    "//\"\"\").explain()\n",
    "//\n",
    "//\n",
    "//spark.sql(\"\"\"\n",
    "//    SELECT * FROM match_details mdb JOIN matches md ON mdb.match_id = md.match_id    \n",
    "//\"\"\").explain()\n",
    "\n",
    "// spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"1000000000000\")\n",
    "\n",
    "// val broadcastFromThreshold = matches.as(\"m\").join(matchDetails.as(\"md\"), $\"m.match_id\" === $\"md.match_id\")\n",
    "//   .select($\"m.completion_date\", $\"md.player_gamertag\",  $\"md.player_total_kills\")\n",
    "//   .take(5)\n",
    "\n",
    "// val explicitBroadcast = matches.as(\"m\").join(broadcast(matchDetails).as(\"md\"), $\"m.match_id\" === $\"md.match_id\")\n",
    "//   .select($\"md.*\", split($\"completion_date\", \" \").getItem(0).as(\"ds\"))\n",
    "\n",
    "val bucketedValues = matchDetailsBucketed.as(\"mdb\").join(matchesBucketed.as(\"mb\"), $\"mb.match_id\" === $\"mdb.match_id\").explain()\n",
    "val values = matchDetailsBucketed.as(\"m\").join(matchesBucketed.as(\"md\"), $\"m.match_id\" === $\"md.match_id\").explain()\n",
    "\n",
    "// explicitBroadcast.write.mode(\"overwrite\").insertInto(\"match_details_bucketed\")\n",
    "\n",
    "// matches.withColumn(\"ds\", split($\"completion_date\", \" \").getItem(0)).write.mode(\"overwrite\").insertInto(\"matches_bucketed\")\n",
    "\n",
    "// spark.sql(bucketedSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8adb02-d5bd-4e84-a671-48991772d233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://2e8125773246:4041\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1734346756353)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------------------+--------------------+-------------+-------------------+--------------+---------+--------------------+\n",
      "|            match_id|               mapid|is_team_game|         playlist_id|     game_variant_id|is_match_over|    completion_date|match_duration|game_mode|      map_variant_id|\n",
      "+--------------------+--------------------+------------+--------------------+--------------------+-------------+-------------------+--------------+---------+--------------------+\n",
      "|11de1a94-8d07-416...|c7edbf0f-f206-11e...|        true|f72e0ef0-7c4a-430...|1e473914-46e4-408...|         true|2016-02-22 00:00:00|          NULL|     NULL|                NULL|\n",
      "|d3643e71-3e51-43e...|cb914b9e-f206-11e...|       false|d0766624-dbd7-453...|257a305e-4dd3-41f...|         true|2016-02-14 00:00:00|          NULL|     NULL|                NULL|\n",
      "|d78d2aae-36e4-48a...|c7edbf0f-f206-11e...|        true|f72e0ef0-7c4a-430...|1e473914-46e4-408...|         true|2016-03-24 00:00:00|          NULL|     NULL|55e5ee2e-88df-465...|\n",
      "|b440069e-ec5f-4f5...|c7edbf0f-f206-11e...|        true|f72e0ef0-7c4a-430...|1e473914-46e4-408...|         true|2015-12-23 00:00:00|          NULL|     NULL|ec3eef73-13e3-4d4...|\n",
      "|1dd475fc-ee6b-4e1...|c93d708f-f206-11e...|        true|0e39ead4-383b-445...|42f97cca-2cb4-497...|         true|2016-04-07 00:00:00|          NULL|     NULL|                NULL|\n",
      "+--------------------+--------------------+------------+--------------------+--------------------+-------------+-------------------+--------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{broadcast, split, lit}\n",
       "matchesBucketed: org.apache.spark.sql.DataFrame = [match_id: string, mapid: string ... 8 more fields]\n",
       "matchDetailsBucketed: org.apache.spark.sql.DataFrame = [match_id: string, player_gamertag: string ... 34 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{broadcast, split, lit}\n",
    "\n",
    "val matchesBucketed = spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/matches.csv\")\n",
    "\n",
    "val matchDetailsBucketed =  spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/match_details.csv\")\n",
    "\n",
    "matchesBucketed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d947a836-bda3-4b45-ac0c-62def729ef78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\" DROP TABLE IF EXISTS bootcamp.matches_bucketed \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77624374-0076-48a8-86f0-c2812d2e7017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\" DROP TABLE IF EXISTS bootcamp.match_details_bucketed \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b3accfc-20a0-4110-85c8-4e2e9843e978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bucketedDDL: String =\n",
       "\"\n",
       "CREATE TABLE IF NOT EXISTS bootcamp.matches_bucketed (\n",
       "    match_id STRING,\n",
       "    is_team_game BOOLEAN,\n",
       "    playlist_id STRING,\n",
       "    completion_date TIMESTAMP\n",
       ")\n",
       "USING iceberg\n",
       "PARTITIONED BY (completion_date, bucket(16, match_id));\n",
       "\"\n",
       "res3: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bucketedDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.matches_bucketed (\n",
    "    match_id STRING,\n",
    "    is_team_game BOOLEAN,\n",
    "    playlist_id STRING,\n",
    "    completion_date TIMESTAMP\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (completion_date, bucket(16, match_id));\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(bucketedDDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510fac0-5d80-47d8-b0da-6435e977ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchesBucketed\n",
    ".select(\n",
    "    $\"match_id\",\n",
    "    $\"is_team_game\",\n",
    "    $\"playlist_id\",\n",
    "    $\"completion_date\"\n",
    ")\n",
    ".limit(1000)\n",
    ".show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1eecb6-ca9a-4b5c-b046-b3a0dd1ff3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Partitioned table on completion_date and the 16 buckets based on match_id\n",
    "matchesBucketed\n",
    ".select(\n",
    "    $\"match_id\",\n",
    "    $\"is_team_game\",\n",
    "    $\"playlist_id\",\n",
    "    $\"completion_date\"\n",
    ")\n",
    ".limit(1000)\n",
    ".write.mode(\"append\")\n",
    ".partitionBy(\"completion_date\")\n",
    ".bucketBy(16, \"match_id\")\n",
    ".saveAsTable(\"bootcamp.matches_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52909714-aed0-4328-9b99-14d595a82ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val bucketedDetailsDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.match_details_bucketed (\n",
    "    match_id STRING,\n",
    "    player_gamertag STRING,\n",
    "    player_total_kills INTEGER,\n",
    "    player_total_deaths INTEGER\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (bucket(16, match_id));\n",
    "\"\"\"\n",
    "spark.sql(bucketedDetailsDDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254f913-bc16-4ee8-a3eb-4e58702d87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Partitioned table on the 16 buckets based on match_id\n",
    "matchDetailsBucketed\n",
    ".select(\n",
    "    $\"match_id\",\n",
    "    $\"player_gamertag\",\n",
    "    $\"player_total_kills\",\n",
    "    $\"player_total_deaths\"\n",
    ")\n",
    ".write.mode(\"append\")\n",
    ".bucketBy(16, \"match_id\")\n",
    ".saveAsTable(\"bootcamp.match_details_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3f1d2-18d7-406f-80a1-63be94d5ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val bucketedValues = matchDetailsBucketed.as(\"mdb\").join(matchesBucketed.as(\"mb\"), $\"mdb.match_id\" === $\"mb.match_id\").explain()\n",
    "bucketedValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf77549-135f-4ae7-b01b-a72f68ff10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Disable broadcast joins\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "\n",
    "matchesBucketed.createOrReplaceTempView(\"matches\")\n",
    "matchDetailsBucketed.createOrReplaceTempView(\"match_details\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM bootcamp.match_details_bucketed mdb JOIN bootcamp.matches_bucketed md \n",
    "    ON mdb.match_id = md.match_id\n",
    "    AND md.completion_date = DATE('2016-01-01')\n",
    "        \n",
    "\"\"\").explain()\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM match_details mdb JOIN matches md ON mdb.match_id = md.match_id    \n",
    "\"\"\").explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
